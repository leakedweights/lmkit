{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda processing allowed: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors: 100%|██████████| 4/4 [02:47<00:00, 41.96s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db6b0af8656e4a2fbe72b51856674b82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['Question: What is a Josephson junction?\\nAnswer: A Josephson junction is a device that consists of two superconducting materials separated by a thin layer of insulating material. When the two superconducting materials are cooled to a temperature below their critical temperature, a current can flow through the junction even though there is a potential difference between the two materials. This phenomenon is known as the Josephson effect, and it has been used in a variety of applications, including superconducting quantum interference devices (SQUIDs) and superconducting quantum computing devices.\\nExplanation: A Josephson junction is a device that consists of two superconducting materials separated by a thin layer of insulating material. When the two superconducting materials are cooled to a temperature below their critical temperature, a current can flow through the junction even though there is a potential difference between the two materials. This phenomenon is known as the Josephson effect, and it has been used in a variety of applications, including superconducting quantum interference devices (SQUIDs) and superconducting quantum computing devices.\\nThe Josephson effect is a quantum mechanical phenomenon that occurs when two superconducting materials are in close proximity to each other. When the two materials are cooled to a temperature below their critical temperature, the superconducting electrons in the two materials can tunnel through the insulating layer and form a current. This current is known as the Josephson current, and it is a result of the quantum mechanical phenomenon of quantum tunneling.\\nThe Josephson effect has been used in a variety of applications, including superconducting quantum interference devices (SQUIDs) and superconducting quantum computing devices. SQUIDs are highly sensitive devices that can detect tiny changes in magnetic fields, and they have been used in a variety of applications, including magnetocardiography and magnetoencephalography. Superconducting quantum computing devices are being developed to perform quantum computations that are faster and more powerful than classical computers.\\nIn summary, a Josephson junction is a device that consists of two superconducting materials separated by a thin layer of insulating material. When the two superconducting materials are cooled to a temperature below their critical temperature, a current can flow through the junction even though there is a potential difference between the two materials. This phenomenon is known as the Josephson effect, and it has been used in a variety of applications, including superconducting quantum interference devices (SQUIDs) and superconducting quantum computing devices. [Note: This answer is based on general knowledge and may not be specific to the given textbook or chapter.]Step-by-step reasoning process: \\n1. Define a Josephson junction: A Josephson junction is a device that consists of two superconducting materials separated by a thin layer of insulating material.\\n2. Explain the Josephson effect: The Josephson effect is a quantum mechanical phenomenon that occurs when two superconducting materials are in close proximity to each other. When the two materials are cooled to a temperature below their critical temperature, the superconducting electrons in the two materials can tunnel through the insulating layer and form a current.\\n3. Describe the applications of the Josephson effect: The Josephson effect has been used in a variety of applications, including superconducting quantum interference devices (SQUIDs) and superconducting quantum computing devices.\\n4. Explain the significance of the Josephson effect: The Josephson effect is a fundamental phenomenon in superconductivity, and it has been used to develop highly sensitive devices and quantum computing devices. [Note: This answer is based on general knowledge and may not be specific to the given textbook or chapter.]Step-by-step reasoning process: \\n1. Define a Josephson junction: A Josephson junction is a device that consists of two superconducting materials separated by a thin layer of insulating material.\\n2. Explain the Josephson effect: The Josephson effect is a quantum mechanical phenomenon that occurs when two superconducting materials are in close proximity to each other. When the two materials are cooled to a temperature below their critical temperature, the superconducting electrons in the two materials can tunnel through the insulating layer and form a current.\\n3. Describe the applications of the Josephson effect: The Josephson effect has been used in a variety of applications, including superconducting quantum interference devices (SQUIDs) and superconducting quantum computing devices.\\n4. Explain the significance of the Josephson effect: The Josephson effect is a fundamental phenomenon in superconductivity, and it has been used to develop highly sensitive devices and quantum computing devices. [Note: This answer is based on general knowledge and may not be specific to the given textbook or chapter.]Step-by-step reasoning process: \\n1. Define a Josephson junction: A Josephson junction is a device that consists of two superconducting materials separated by a thin layer of insulating material.\\n2. Explain the Josephson effect: The Josephson effect is a quantum mechanical phenomenon that occurs when',\n",
       " \"Question: What is the highest point of the Pamirs?\\nAnswer: Ismoil Somoni Peak\\nThe Ismoil Somoni Peak is the highest point of the Pamirs, with an elevation of 7,495 meters (24,590 ft) above sea level. It is located in Tajikistan and is also known as Peak Communism. The peak is named after Ismoil Somoni, the founder of the Samanid Empire in the 9th century. The Pamirs are a mountain range in Central Asia, and the Ismoil Somoni Peak is a prominent feature of the range. Climbing the peak is a significant achievement for mountaineers due to its high altitude and challenging terrain. The peak is also an important cultural and historical site, reflecting the rich history and heritage of the region. The Ismoil Somoni Peak is a popular destination for adventure seekers and those interested in exploring the natural beauty and cultural significance of the Pamirs. The peak is also a testament to the region's natural beauty and the achievements of mountaineers who have successfully climbed it. The Ismoil Somoni Peak is a significant landmark in the Pamirs, and its elevation makes it a notable feature of the mountain range. The peak's name reflects the cultural and historical significance of the region, and its natural beauty makes it a popular destination for those interested in exploring the outdoors. The Ismoil Somoni Peak is an important part of the Pamirs' natural and cultural heritage, and its elevation makes it a notable feature of the mountain range. The peak is a popular destination for adventure seekers and those interested in exploring the natural beauty and cultural significance of the region. The Ismoil Somoni Peak is a significant landmark in the Pamirs, and its elevation makes it a notable feature of the mountain range. The peak's name reflects the cultural and historical significance of the region, and its natural beauty makes it a popular destination for those interested in exploring the outdoors. The Ismoil Somoni Peak is an important part of the Pamirs' natural and cultural heritage, and its elevation makes it a notable feature of the mountain range. The peak is a popular destination for adventure seekers and those interested in exploring the natural beauty and cultural significance of the region. The Ismoil Somoni Peak is a significant landmark in the Pamirs, and its elevation makes it a notable feature of the mountain range. The peak's name reflects the cultural and historical significance of the region, and its natural beauty makes it a popular destination for those interested in exploring the outdoors. The Ismoil Somoni Peak is an important part of the Pamirs' natural and cultural heritage, and its elevation makes it a notable feature of the mountain range. The peak is a popular destination for adventure seekers and those interested in exploring the natural beauty and cultural significance of the region. The Ismoil Somoni Peak is a significant landmark in the Pamirs, and its elevation makes it a notable feature of the mountain range. The peak's name reflects the cultural and historical significance of the region, and its natural beauty makes it a popular destination for those interested in exploring the outdoors. The Ismoil Somoni Peak is an important part of the Pamirs' natural and cultural heritage, and its elevation makes it a notable feature of the mountain range. The peak is a popular destination for adventure seekers and those interested in exploring the natural beauty and cultural significance of the region. The Ismoil Somoni Peak is a significant landmark in the Pamirs, and its elevation makes it a notable feature of the mountain range. The peak's name reflects the cultural and historical significance of the region, and its natural beauty makes it a popular destination for those interested in exploring the outdoors. The Ismoil Somoni Peak is an important part of the Pamirs' natural and cultural heritage, and its elevation makes it a notable feature of the mountain range. The peak is a popular destination for adventure seekers and those interested in exploring the natural beauty and cultural significance of the region. The Ismoil Somoni Peak is a significant landmark in the Pamirs, and its elevation makes it a notable feature of the mountain range. The peak's name reflects the cultural and historical significance of the region, and its natural beauty makes it a popular destination for those interested in exploring the outdoors. The Ismoil Somoni Peak is an important part of the Pamirs' natural and cultural heritage, and its elevation makes it a notable feature of the mountain range. The peak is a popular destination for adventure seekers and those interested in exploring the natural beauty and cultural significance of the region. The Ismoil Somoni Peak is a significant landmark in the Pamirs, and its elevation makes it a notable feature of the mountain range. The peak's name reflects the cultural and historical significance of the region, and its natural beauty makes it a popular destination for those interested in exploring the outdoors. The Ismoil Somoni Peak is an important part of the Pamirs' natural and cultural heritage, and its elevation makes it a notable feature of the mountain range. The peak is a popular destination for adventure seekers\"]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from jax import random\n",
    "from flax.core import FrozenDict\n",
    "\n",
    "from lmkit.model import sampler, config as config_lib\n",
    "from lmkit.tools import compat\n",
    "\n",
    "repo = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "model_dir = \"models/llama3\"\n",
    "\n",
    "if not os.path.exists(model_dir) or not os.listdir(model_dir):\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()\n",
    "\n",
    "    compat.from_hf(repo, model_dir, token=os.environ[\"HF_API_TOKEN\"])\n",
    "\n",
    "params = compat.params_to_lmkit(compat.gather_for_jax(model_dir))\n",
    "params = FrozenDict(params)\n",
    "config = compat.load_lmkit_config(f\"{model_dir}/config.json\")\n",
    "config = config_lib.extend_llama(config)\n",
    "\n",
    "tokenizer = compat.to_lmkit_tokenizer(\n",
    "    f\"{model_dir}/tokenizer.json\", f\"{model_dir}/generation_config.json\"\n",
    ")\n",
    "\n",
    "\n",
    "prompts = [\n",
    "    \"Question: What is a Josephson junction?\\nAnswer:\",\n",
    "    \"Question: What is the highest point of the Pamirs?\\nAnswer:\",\n",
    "]\n",
    "\n",
    "sampler.generate(\n",
    "    inputs=prompts,\n",
    "    max_new_tokens=1000,\n",
    "    tokenizer=tokenizer,\n",
    "    params=params,\n",
    "    config=config,\n",
    "    random_key=random.key(0),\n",
    "    return_text=True,\n",
    "    verbose=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"models/demo\"\n",
    "tokenizer_path = f\"{model_dir}/tokenizer.json\"\n",
    "generation_config_path = f\"{model_dir}/generation_config.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Applied 'train' post-processor (BOS+EOS).\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from lmkit.tools import data, trainer, compat\n",
    "\n",
    "# 1. Extract dataset\n",
    "\n",
    "datasource_file = \"data/shakespeare.txt\"\n",
    "with open(datasource_file, \"r\") as f:\n",
    "    text = f.read()\n",
    "data_iter = text.split(\"\\n\")\n",
    "\n",
    "batch_size=2048\n",
    "dataset_dir = \"data/dataset\"\n",
    "\n",
    "if not os.path.exists(dataset_dir) or not os.listdir(dataset_dir):\n",
    "    data.to_arrayrecord(\n",
    "        data_iter = data_iter,\n",
    "        out_dir=dataset_dir,\n",
    "        encode_fn=lambda x: x.encode(\"utf-8\"),\n",
    "    )\n",
    "\n",
    "# 2. Train tokenizer\n",
    "vocab_size = 2048\n",
    "min_frequency = 2\n",
    "\n",
    "tokenizer_dataset = data.grain_dataset_from(\n",
    "    arrayrecord_dir=dataset_dir,\n",
    "    batch_size=batch_size,\n",
    "    map_fn=lambda x: x.decode(\"utf-8\"),\n",
    ")\n",
    "data_iterator = iter(tokenizer_dataset)\n",
    "\n",
    "tokenizer = trainer.train_tokenizer(\n",
    "    iterator=data_iterator,\n",
    "    vocab_size=vocab_size,\n",
    "    save_dir=model_dir,\n",
    "    generation_config={},\n",
    "    min_frequency=min_frequency,\n",
    ")\n",
    "\n",
    "tokenizer = compat.load_tokenizer(\n",
    "    tokenizer_path=tokenizer_path,\n",
    "    mode=\"train\",\n",
    "    generation_config_file=generation_config_path,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "621c9a6584fa4599a8caaa168515895c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training completed. Final parameters and optimizer state returned.\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from flax.core import FrozenDict\n",
    "import logging\n",
    "from lmkit.tools import data\n",
    "\n",
    "jax.config.update(\"jax_debug_nans\", True)\n",
    "\n",
    "config = FrozenDict({\n",
    "    \"num_layers\": 12,\n",
    "    \"num_heads\": 12,\n",
    "    \"num_kv_heads\": 12,\n",
    "    \"hidden_size\": 768,\n",
    "    \"intermediate_size\": 3072,\n",
    "    \"act_fn\": jax.nn.silu,\n",
    "    \"vocab_size\": tokenizer.vocab_size,\n",
    "    \"max_position_embeddings\": 2048,\n",
    "    \"rope_base\": 100_000,\n",
    "    \"norm_eps\": 1e-6,\n",
    "    \"io_tying\": True,\n",
    "\n",
    "})\n",
    "\n",
    "batch_size = 2048\n",
    "num_steps = 500\n",
    "log_granularity = 50\n",
    "save_granularity = 200\n",
    "ckpt_dir = \"checkpoints\"\n",
    "dataset_dir = \"data/dataset\"\n",
    "\n",
    "def batch_map_fn(batch_text, min_final_len: int = 2):\n",
    "    if tokenizer.pad_token_id is None:\n",
    "        raise ValueError(\"Tokenizer must have pad_token_id set for padding.\")\n",
    "\n",
    "    encoded = tokenizer.encode_batch_fast(batch_text)\n",
    "    if not encoded:\n",
    "        return None\n",
    "\n",
    "    logging.info(\"Decoded: {tokenizer.decode_batch(encoded, skip_special_tokens=False)}\")\n",
    "\n",
    "    max_len = max(len(item.ids) for item in encoded) if encoded else 0\n",
    "    if max_len == 0:\n",
    "        logging.debug(\"Skipping batch: max sequence length after tokenization is 0.\")\n",
    "        return None\n",
    "\n",
    "    ids = [\n",
    "        item.ids + [tokenizer.pad_token_id] * (max_len - len(item.ids))\n",
    "        for item in encoded\n",
    "    ]\n",
    "    initial_batch_tokens = jnp.array(ids, dtype=jnp.int32)\n",
    "\n",
    "    current_len = initial_batch_tokens.shape[1]\n",
    "    pad_amount = 1 - (current_len % 2)\n",
    "    paddings = ((0, 0), (0, pad_amount))\n",
    "\n",
    "    padded_tokens_for_slicing = jnp.pad(\n",
    "        initial_batch_tokens,\n",
    "        paddings,\n",
    "        mode=\"constant\",\n",
    "        constant_values=tokenizer.pad_token_id,\n",
    "    )\n",
    "    odd_len = padded_tokens_for_slicing.shape[1]\n",
    "\n",
    "    final_len = odd_len - 1\n",
    "    if final_len < min_final_len:\n",
    "        logging.debug(\n",
    "            f\"Skipping batch: final sequence length ({final_len}) < min_final_len ({min_final_len}).\"\n",
    "        )\n",
    "        return None\n",
    "\n",
    "    positions_for_slicing = jnp.where(\n",
    "        padded_tokens_for_slicing != tokenizer.pad_token_id, jnp.arange(odd_len), -1\n",
    "    )\n",
    "\n",
    "    input_ids = padded_tokens_for_slicing[:, :-1]\n",
    "    input_positions = positions_for_slicing[:, :-1]\n",
    "    target_ids = padded_tokens_for_slicing[:, 1:]\n",
    "\n",
    "    return FrozenDict(\n",
    "        {\n",
    "            \"input_ids\": input_ids.astype(jnp.int32),\n",
    "            \"positions\": input_positions.astype(jnp.int32),\n",
    "            \"target_ids\": target_ids.astype(jnp.int32),\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "dataset = data.grain_dataset_from(\n",
    "    arrayrecord_dir=dataset_dir,\n",
    "    batch_size=batch_size,\n",
    "    map_fn=lambda x: x.decode(\"utf-8\"),\n",
    "    batch_map_fn=batch_map_fn,\n",
    ")\n",
    "dataset = dataset.repeat(50)\n",
    "\n",
    "final_params, final_opt_state = trainer.train_model(\n",
    "    config=config,\n",
    "    data_iterator=iter(dataset.to_iter_dataset()),\n",
    "    num_steps=num_steps,\n",
    "    learning_rate=1e-2,\n",
    "    log_every=log_granularity,\n",
    "    save_every=save_granularity,\n",
    "    checkpoint_dir=ckpt_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied 'inference' post-processor (BOS only).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c27bff257ef4031a6fa149e234665b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos>first citizen:<eos>is,<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>st.<eos> not not you have i'll not,<eos> be the father, and<eos><eos> to,<eos><eos> a,<eos>.<eos> his good,<eos>,<eos><eos>, and be the king<eos>,<eos> to not, the good a own ded,<eos>;<eos>.<eos>,<eos>,<eos><eos>,<eos> to the.<eos>,<eos>,<eos>.<eos>s,<eos>, and a star\n"
     ]
    }
   ],
   "source": [
    "from lmkit.model import sampler\n",
    "from jax import random\n",
    "\n",
    "sampling_tokenizer = compat.load_tokenizer(\n",
    "    tokenizer_path, mode=\"inference\", generation_config_file=generation_config_path\n",
    ")\n",
    "\n",
    "prompts = [\n",
    "    \"First\"\n",
    "]\n",
    "\n",
    "generated = sampler.generate(\n",
    "    inputs=prompts,\n",
    "    max_new_tokens=100,\n",
    "    tokenizer=sampling_tokenizer,\n",
    "    params=final_params,\n",
    "    config=config,\n",
    "    random_key=random.key(0),\n",
    "    return_text=False,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(sampling_tokenizer.decode(generated[0], skip_special_tokens=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
